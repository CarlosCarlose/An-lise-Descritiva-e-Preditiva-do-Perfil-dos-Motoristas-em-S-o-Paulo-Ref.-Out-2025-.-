# InteligÃªncia de Mercado para Locadoras: ExpansÃ£o de Frotas e Lead Scoring (SP 2025)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-visuals-777BB4?style=for-the-badge&logo=seaborn&logoColor=white)
![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success?style=for-the-badge)

## ðŸ“‹ Resumo Executivo

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o tÃ©cnica de uma soluÃ§Ã£o de **Data Science & Strategic Analytics** desenvolvida para otimizar a alocaÃ§Ã£o de ativos no mercado de **LocaÃ§Ã£o de VeÃ­culos (Frotas)** em SÃ£o Paulo.

Utilizando a base censitÃ¡ria de condutores habilitados (Outubro/2025) do Detran-SP, o projeto aplica um pipeline de **Engenharia de Dados** e **Machine Learning** para solucionar o problema de "Cold Start" na expansÃ£o de agÃªncias. O modelo transforma dados brutos em indicadores de **Volume (Market Density)** e **PropensÃ£o (Lead Scoring)**, permitindo que locadoras identifiquem onde instalar novos pÃ¡tios e qual perfil demogrÃ¡fico priorizar em campanhas de marketing para maximizar o LTV (Lifetime Value) e reduzir a sinistralidade.

---

## ðŸ“‚ Estrutura do RepositÃ³rio

O projeto foi arquitetado em mÃ³dulos independentes para garantir a integridade do processamento e a reprodutibilidade da anÃ¡lise visual.

| Arquivo | FunÃ§Ã£o TÃ©cnica | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `Fase_2_BI.ipynb` | **Backend (Engenharia)** | Pipeline de ingestÃ£o, limpeza (ETL), engenharia de atributos e treinamento do modelo *Random Forest*. Gera o CSV final. |
| `data_visualization.ipynb` | **Frontend (Analytics)** | Notebook de apresentaÃ§Ã£o. Consome o CSV processado e gera os grÃ¡ficos executivos (Matriz de Calor, Rankings e Dashboard Interativo). |
| `baseBICNH_dashboard_2025_fase2.csv` | **Dataset Processado** | Base de dados tratada e enriquecida com os Scores Preditivos, pronta para consumo analÃ­tico. |

---

## âš ï¸ Nota sobre o Dashboard Interativo

No final do notebook de visualizaÃ§Ã£o (`data_visualization.ipynb`), existe uma ferramenta de **Data Mining Interativa** (Menu de Cidades) desenvolvida com a biblioteca `ipywidgets`.

> **AtenÃ§Ã£o:** Como o GitHub renderiza notebooks como pÃ¡ginas estÃ¡ticas, **os menus suspensos e botÃµes nÃ£o funcionam na prÃ©-visualizaÃ§Ã£o do navegador**, podendo aparecer como cÃ³digo vazio ou mensagem de erro de renderizaÃ§Ã£o.

Para utilizar o filtro dinÃ¢mico:
1.  Baixe o notebook ou abra-o no **Google Colab**.
2.  Execute todas as cÃ©lulas (`Runtime > Run All`).
3.  VÃ¡ atÃ© a Ãºltima seÃ§Ã£o ("AnÃ¡lise TÃ¡tica por Cidade") para interagir com o menu e filtrar os dados por municÃ­pio.

---

## âš™ï¸ Arquitetura e Metodologia

A soluÃ§Ã£o foi desenvolvida sob uma arquitetura **Serverless em Nuvem**, utilizando Python para todo o ciclo de vida do dado, eliminando dependÃªncias de ferramentas proprietÃ¡rias de BI.

### Pipeline de Dados (Fluxo de ExecuÃ§Ã£o)

O pipeline executa as seguintes etapas sequenciais:

#### 1. IngestÃ£o e Tratamento (ETL)
* **Filtros de NegÃ³cio:** AplicaÃ§Ã£o de regex para isolar condutores da **Categoria B** (aptos a dirigir automÃ³veis), descartando categorias exclusivas de moto ou carga pesada, alinhando a anÃ¡lise ao portfÃ³lio das locadoras.
* **Limpeza:** ExclusÃ£o de registros com flag `condutor_bloqueado = 'S'`, garantindo que a anÃ¡lise reflita apenas a frota ativa.

#### 2. Engenharia de Atributos (Feature Engineering)
TransformaÃ§Ã£o dos dados transacionais em uma **Tabela Mestra de Perfis**.
* **Agrupamento:** ClusterizaÃ§Ã£o por `MunicÃ­pio`, `Faixa EtÃ¡ria` e `GÃªnero`.
* **CÃ¡lculo de KPI:** GeraÃ§Ã£o da **Taxa de AdesÃ£o Regional (KPI 1)** atravÃ©s da pivotagem de dados.

#### 3. Modelagem Preditiva (Lead Scoring)
ImplementaÃ§Ã£o de algoritmo supervisionado para cÃ¡lculo do **Score de PropensÃ£o (KPI 3)**.
* **Algoritmo:** **Random Forest Regressor** (*Scikit-Learn*).
* **Justificativa:** A escolha por Florestas AleatÃ³rias deve-se Ã  sua capacidade de capturar relaÃ§Ãµes nÃ£o-lineares (ex: o risco e a propensÃ£o variam drasticamente entre jovens e adultos) e sua robustez para inferir scores em municÃ­pios com baixa amostragem estatÃ­stica, onde a taxa bruta (KPI 1) poderia ser enganosa.

#### 4. VisualizaÃ§Ã£o de Dados (Data Viz)
GeraÃ§Ã£o de grÃ¡ficos estÃ¡ticos de alta fidelidade (**Seaborn**) com identidade visual executiva ("Dark/Tech"), focados em responder perguntas de negÃ³cio sobre Ociosidade e Custo de AquisiÃ§Ã£o (CAC).

---

## ðŸ“Š DicionÃ¡rio de Dados (Output Final)

DescriÃ§Ã£o das variÃ¡veis estratÃ©gicas contidas no arquivo `baseBICNH_dashboard_2025_fase2.csv`:

| VariÃ¡vel | Tipo | AplicaÃ§Ã£o no NegÃ³cio (Locadoras) |
| :--- | :--- | :--- |
| `Cidade` | String | Filtragem geogrÃ¡fica para expansÃ£o de rede fÃ­sica e logÃ­stica. |
| `Faixa_Etaria` | String | SegmentaÃ§Ã£o para anÃ¡lise de Risco (Jovens vs Adultos) e LTV. |
| `Genero` | String | SegmentaÃ§Ã£o demogrÃ¡fica para personalizaÃ§Ã£o de campanhas. |
| `KPI_Volume_Demanda` | Int64 | **(KPI 2 - Volume)** Define o tamanho do pÃ¡tio/estoque necessÃ¡rio na regiÃ£o (CAPEX). |
| `KPI_Taxa_Conversao` | Float64 | **(KPI 1 - EficiÃªncia)** DiagnÃ³stico histÃ³rico. Mede a porcentagem real de adesÃ£o em cada micro-regiÃ£o. |
| `KPI_Score_Propensao` | Float64 | **(KPI 3 - Qualidade)** Ãndice calculado via **Machine Learning**. Corrige distorÃ§Ãµes estatÃ­sticas de municÃ­pios pequenos (generalizaÃ§Ã£o) e projeta a probabilidade de adesÃ£o baseada no padrÃ£o do perfil (0.0 a 1.0). |

---

## ðŸ› ï¸ Requisitos para ReproduÃ§Ã£o

Para executar o cÃ³digo fonte deste projeto, sÃ£o necessÃ¡rias as seguintes bibliotecas Python:

```python
pandas>=1.3.5
numpy>=1.21.6
scikit-learn>=1.0.2
seaborn>=0.11.2
ipywidgets>=7.6.5
